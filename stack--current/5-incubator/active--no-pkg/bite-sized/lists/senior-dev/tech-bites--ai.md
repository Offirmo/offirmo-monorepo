+++ 2023 https://9elements.com/blog/ai-glossary/
+++ https://platform.openai.com/docs/introduction/key-concepts
+++ official OpenAI doc https://platform.openai.com/docs/introduction
??? https://github.com/SkalskiP/courses crème de la crème of AI courses
[ ] https://aleteia.org/tag/artificial-intelligence/
[ ] https://www.perspectiveapi.com/
[ ] https://www.sbert.net/
[ ] People + AI Guidebook https://pair.withgoogle.com/guidebook/patterns
A::B Prompting Challenge: $10k to prove me wrong! https://twitter.com/VictorTaelin/status/1776677635491344744 https://twitter.com/headinthebox/status/1777016124141650254
Agentic AI systems = AI systems that can pursue complex goals with limited direct supervision https://openai.com/research/practices-for-governing-agentic-ai-systems
agents -- principals
agents = you provide a goal, They'll generate a task list and get to work https://zapier.com/blog/ai-agent/
AGI -- ANI -> AGI -> ASI = narrow(weak) / general(strong) / super[human](strong)
AGI ~ strong AI = can independently learn new problem-solving strategies that are not explicitly included in its original model or training data
AI - Artificial intelligence = intentionally vague term / "solving tasks or problems by computers/machines, which require a form of human-like intelligence"
AI -- weak AI = task specific
AI 50 2023 https://www.forbes.com/lists/ai50/?sh=5f9503cc290f
AI Driven Organisations (AIDO)
AI gateway = convenient self-service integration point for internal teams who want to utilise turnkey AI APIs, proxy for the external and internal AI offerings + additional set of capabilities that empower usage and tracking of AI functionalities at an enterprise level.
AI winter
alignment -- generic = conform to predefined values, usually ethical or social values, Truthfulness, Harmlessness, Helpfulness
alignment -- super alignment =  https://openai.com/blog/introducing-superalignment  https://openai.com/blog/superalignment-fast-grants
alignment =  making AI do what its users want it to do (and nothing more) see also "paper clip"
annotation https://www.peopleforai.com/ https://www.isahit.com/
API -- Gemini https://ai.google.dev/docs/gemini_api_overview
applications -- legacy code https://martinfowler.com/articles/legacy-modernization-gen-ai.html
applied -- 2024/06 Slack Enzyme to RTL https://slack.engineering/balancing-old-tricks-with-new-feats-ai-powered-conversion-from-enzyme-to-react-testing-library-at-slack/
assistant = entities capable of performing tasks for users. assistants operate based on the instructions in a context window + tools https://platform.openai.com/docs/introduction/assistants
attention
attention -- flash attention = ???
BERT
bias
BLOOM = "BigScience Large Open-science Open-access Multilingual Language Model" = deprecated former big model
BM25 (Best Matching 25) = a ranking function that uses lexical matching to find precise word or phrase matches. It's particularly effective for queries that include unique identifiers or technical terms https://www.anthropic.com/news/contextual-retrieval
BPE Byte Pair Encoding is a way of converting text into tokens
canny edge (generative AI) https://en.wikipedia.org/wiki/Canny_edge_detector
capability stack = interaction, generation, automation, recommendation, prediction, classification, recognition
chain-of-thoughts https://arxiv.org/abs/2201.11903
chat -- ChatGPT
chat -- Claude https://claude.ai/chat/
chat -- Gemini
chat -- GroqChat https://groq.com/
chatbots = the reason why AI exploded in 2023
citation accuracy
common sense https://commonsense.run/
context
Contextual Language Models (CLMs) Contextual.ai
control vector https://vgel.me/posts/representation-engineering/
ControlNet = a type of model for controlling image diffusion models by conditioning the model with an additional input image https://huggingface.co/docs/diffusers/using-diffusers/controlnet https://github.com/lllyasviel/ControlNet
cross encoder https://www.sbert.net/examples/applications/cross-encoder/README.html
dataset  https://www.fatml.org/media/documents/datasheets_for_datasets.pdf
deep reinforcement learning (deep RL) course: https://spinningup.openai.com/
delvish dialect https://bruces.medium.com/preliminary-notes-on-the-delvish-dialect-by-bruce-sterling-ce68a476247b
developer vs sociotechnic vs project organizer
diffusers
diffusion
Discrete Variational Auto Encoder (VAE) for image generation? https://medium.com/@jaswanth04/discrete-variational-auto-encoder-explained-41493ebe294d
DL Deep Learning (NN)
effort paradox -- optimal human touchpoints
effort paradox https://uxdesign.cc/the-effort-paradox-in-ai-design-996a0bc2f7f6
embeddings = raw underlying representation of a concept preserving aspects of its content and/or its meaning (Of course it's model-dependent?) https://platform.openai.com/docs/guides/embeddings/use-cases
fine-tuning
frontier AI -- OpenAI = highly capable foundation models that could possess dangerous capabilities sufficient to pose severe risks to public safety https://openai.com/index/frontier-ai-regulation/
frontier AI = bleeding edge models
function calling (bad name) = connect large language models to external tools https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling https://platform.openai.com/docs/guides/function-calling
generative AI
generative AI gold rush
glimpsing the shoggoth / forgetting the mask = situations in which the A.I. exhibits "unhinged" or unexpected behaviors that bypass its safety restrictions https://en.wikipedia.org/wiki/Shoggoth#In_popular_culture
GLUE language understanding benchmark
GPT "Generative Pre-trained Transformer" = understand language (natural & formal)
Grounded Generation = see RAG
hallucinations -- "King Renoit" https://zapier.com/blog/ai-hallucinations/
hallucinations -- "Vectara's Hallucination Evaluation Model"
hallucinations -- leaderboard https://github.com/vectara/hallucination-leaderboard
helpful, harmless and honest
HHH helpful, honest, and harmless
Hierarchical Navigable Small World (HNSW) = graph for vector search https://www.pinecone.io/learn/series/faiss/hnsw/
Hugging Face = "the GitHub of machine learning" = the collaboration platform for the machine learning community https://www.techtarget.com/whatis/definition/Hugging-Face
huggingface.co "space"
illusion of understanding = hypothesis that LLMs don't actually perform formal reasoning and instead mimic it with probabilistic pattern-matching of the closest similar data seen in their vast training sets https://arstechnica.com/ai/2024/10/llms-cant-perform-genuine-logical-reasoning-apple-researchers-suggest/
in-context learning = ~long prompt / many shots https://www.anthropic.com/research/many-shot-jailbreaking
inference
inference = what happens when we prompt
issues -- babysitting the AI = don’t want to spend more time correcting the AI than using it
issues -- bad data = Garbage In, Garbage Out
issues -- Inaccuracy (answer quality)
issues -- Language = not English
issues -- privacy, control
JAX
knowledge cutoff
langchain = a framework for developing applications powered by language models https://python.langchain.com/docs/get_started/introduction
latency
laziness = cases where the model doesn’t complete a task https://openai.com/blog/new-embedding-models-and-api-updates
learning -- Transfer learning = a technique where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task
lib -- JAX https://github.com/google/jax
lib -- PyTorch https://pytorch.org/
lib -- TensorFlow https://www.tensorflow.org/ (deprecated?)
lib -- Transformers https://github.com/huggingface/transformers  https://huggingface.co/blog/noob_intro_transformers
LLM -- "Language Model for Dialogue Applications" (LaMDA) 137B model from Google AI
LLM -- "Pathways Language Model" (PaLM) 540B model from Google AI
LLMs - large language models
machine learning feature = ‘feature’, in this context might be something like ‘number of times UserA has viewed Issue123 in the last week', which may be a useful signal to a machine learning model
machine learning feature store = ex. Tecton https://docs.tecton.ai/docs/introduction
MCP https://modelcontextprotocol.io/tutorials/building-mcp-with-llms
mind tax https://www.fastcompany.com/91242373/the-cognitive-cost-of-ai
Mixture of Experts (MoE) = combining models https://huggingface.co/blog/moe
Mixture of Experts -- "sparse mixture of experts" (SMoE)
ML - machine learning https://en.wikipedia.org/wiki/Machine_learning ~"subfield of AI that describes AI using data and algorithms without a programmer explicitly specifying the solution path through program code"
moat - We have no moat https://www.semianalysis.com/p/google-we-have-no-moat-and-neither
model (NN) = sort of snapshot of a trained neural network / brain = NN (structure + parameters) https://huggingface.co/docs/hub/models
model -- efficiency
model -- foundational = a big one pre-trained on vast resources
model -- transformer model
NLG Natural Language Generation
NLP Natural Language Processing
NN Neural Networks "computer architecture inspired by the human brain"
OpenAI GPTs = custom versions of ChatGPT that you can create for a specific purpose with instructions, expanded knowledge, and custom capabilities
paper -- "attention is all you need" https://arxiv.org/pdf/1706.03762.pdf
parameter (NN)
parameter -- hyperparameter = values provided to the model from the outside to make adjustments that can influence the learning process and its performance, among other things
Pathways = broader AU architecture underpinning PaLM
Pathways Autoregressive Text-to-Image model (Parti), is an autoregressive text-to-image generation model that achieves high-fidelity photorealistic image generation and supports content-rich synthesis involving complex compositions and world knowledge.
player -- Google AI https://ai.google/
player -- https://modal.com/blog/embedding-wikipedia
player -- https://vectara.com/ = RAG
player -- https://www.adept.ai/
pre-training
processing -- GPU = Graphics Processing Units
processing -- GPU vs TPU vs LPU https://medium.com/@harishramkumar/comparing-gpu-vs-tpu-vs-lpu-the-battle-of-ai-processors-2cf4548c4a62
processing -- LPU = Language Processing Units
processing -- Meta Training and Inference Accelerator (MTIA) https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/
processing -- TPU = Tensor Processing Units
prompt -- design -- anthropic https://docs.anthropic.com/claude/docs/introduction-to-prompt-design
prompt -- design -- google https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=en
prompt -- generation https://www.anthropic.com/news/evaluate-prompts
prompt -- optimization https://app.hamming.ai/prompt-optimizer
prompt -- ROC = [Role] + [Output] + [Context], ex. You are an engineering manager, how many story points do you think this will be and why? https://community.atlassian.com/t5/Jira-Software-articles/Be-an-AI-Rockstar-Prompts-in-Jira-Software/ba-p/2636811
Pytorch
RAG 2.0 https://medium.com/towards-artificial-intelligence/rag-2-0-finally-getting-rag-right-f74d0194a720
rat race https://www.cnbc.com/2024/05/03/ai-engineers-face-burnout-as-rat-race-to-stay-competitive-hits-tech.html
ReAct flow
reasoning trace https://arstechnica.com/information-technology/2024/09/openai-threatens-bans-for-probing-new-ai-models-reasoning-process/
regulation -- European AI act https://www.reddit.com/r/ArtificialInteligence/comments/1fqmcds/i_worked_on_the_eus_artificial_intelligence_act/
Representation Engineering = calculating a "control vector" that can be read from or added to model activations during inference to interpret or control the model's behavior https://vgel.me/posts/representation-engineering/
research directions -- honesty, chain-of-thought faithfulness, adversarial robustness, evals and testbeds...
research directions -- Interpretability: How can we understand model internals? And can we use this to e.g. build an AI lie detector?
research directions -- Scalable oversight: How can we use AI systems to assist humans in evaluating the outputs of other AI systems on complex tasks?
research directions -- Weak-to-strong generalization: Humans will be weak supervisors relative to superhuman models. Can we understand and control how strong models generalize from weak supervision?
Retrieval-Augmented Generation (RAG) = a methodology that assists Large Language Models (LLMs) generate accurate and up-to-date information https://medium.com/@rushing_andrei/building-a-basic-rag-retrieval-augmented-generation-system-in-a-rails-app-247ccce5d1d2
RLHF reinforcement learning from human feedback
SageMaker (AWS)
Searle's Chinese Room https://plato.stanford.edu/entries/chinese-room/
security -- Freysa "approveTransfer" https://x.com/jarrodwattsdev/status/1862299845710757980
singularity
skilled pragmatist https://cutlefish.substack.com/p/tbm-271-the-biggest-untapped-opportunity
sleeper agents (security) https://www.anthropic.com/research/probes-catch-sleeper-agents
sleeper agents -- defection probes https://www.anthropic.com/research/probes-catch-sleeper-agents
slop = unwanted AI generated content https://simonwillison.net/2024/May/8/slop/
Snowflake Arctic https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/
sociotechnic = skilled at analyzing the interaction of technology and society long-term: lawyers, ethicists, sociologists, or rights advocates
Stable Diffusion
superintelligence "AI vastly smarter than humans" https://openai.com/research/weak-to-strong-generalization
Support Vector Machines
symbolic logic
synthesizer = sound generation
T5X is a modular, composable, research-friendly framework for high-performance, configurable, self-service training, evaluation, and inference of sequence models (starting with language) at many scales.
tasks -- vision -- Depth Estimation
tasks -- vision -- Image Classification
tasks -- vision -- Image Segmentation
tasks -- vision -- Image-to-Image
tasks -- vision -- Mask Generation
tasks -- vision -- Object Detection
tasks -- vision -- Unconditional Image Generation
tasks -- vision -- Video Classification
tasks -- vision -- Zero-Shot Image Classification
tasks -- vision -- Zero-Shot Object Detection
temperature
temptation to over-automate = need balance vs overwork https://uxdesign.cc/the-effort-paradox-in-ai-design-996a0bc2f7f6
tensor ??
TensorFlow = outdated, this is all pyTorch now. See also JAX
Text generation models -> see GPT https://platform.openai.com/docs/introduction/text-generation-models
tokenization https://platform.openai.com/tokenizer vs https://github.com/huggingface/tokenizers
tokenizer -- sentencepiece https://github.com/google/sentencepiece
tokenizer -- tiktoken https://tiktokenizer.vercel.app/
tokenizer = good explanation https://towardsdatascience.com/a-comprehensive-guide-to-subword-tokenisers-4bbd3bad9a7c
tokens https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them
training (NN) -- Overfitting
training (NN) -- Reinforcement Learning
training (NN) -- supervised learning
training (NN) -- transfer learning = see fine-tuning
training (NN) -- unsupervised learning
training (NN) = iterative process in which data is passed to a neural network + parameters of the neural network are adjusted to achieve an optimal solution for the given problem. a dataset is required
training data -- illegal https://www.pcgamer.com/gaming-industry/court-documents-show-not-only-did-meta-torrent-terabytes-of-pirated-books-to-train-ai-models-employees-wouldnt-stop-emailing-each-other-about-it-torrenting-from-a-corporate-laptop-doesnt-feel-right/
Trainium
transfer learning
transformers "a new type of NLP model that demolished the reading comprehension abilities of both humans and the best AI incumbent at the time" ~pattern recognition techniques
transformers (hugging face) = a magic python library that can auto-download models on demand https://github.com/huggingface/transformers BUT it's for research, not prod (no unified API for ex.)
Turing test
vector -- difference with embedding??
vector database
vector database -- https://weaviate.io/
vector database -- https://www.pinecone.io
vector database -- Qdrant https://qdrant.tech/blog/series-a-funding-round/
weak-to-strong generalization https://openai.com/research/weak-to-strong-generalization
